# Speaches Configuration for RunPod NVIDIA GPU
# Usage: set -a && source config/runpod.env && set +a

# Server Configuration
UVICORN_HOST=0.0.0.0
UVICORN_PORT=8000

# Whisper Model Settings (CUDA mode for NVIDIA GPU)
WHISPER__INFERENCE_DEVICE=cuda
WHISPER__DEVICE_INDEX=0
WHISPER__COMPUTE_TYPE=float16
WHISPER__MODEL=Systran/faster-whisper-large-v3

# Model TTL Settings (-1 = never unload, keeps model in memory)
STT_MODEL_TTL=-1
TTS_MODEL_TTL=300
VAD_MODEL_TTL=-1

# UI Settings
ENABLE_UI=true

# Logging
LOG_LEVEL=info

# Optional: Preload model on startup (reduces first request latency)
# PRELOAD_MODELS=["Systran/faster-whisper-large-v3"]
